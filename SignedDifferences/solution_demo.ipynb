{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signed Differences Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we demonstrate our solution in four different setups:\n",
    "- Positive:\n",
    "    - No Noise\n",
    "    - With Noise\n",
    "- Signed:\n",
    "    - No Noise\n",
    "    - With Noise\n",
    "\n",
    "The data here is a difference matrix $D$ based on a vector $X$ of numbers which are either positive, or a mix of positive and negative numbers (hence the term \"signed\"). The difference matrix $D$ may or may not be contaminated with a factor of $10^{-5}$ of a vector of Gaussian noise. \n",
    "\n",
    "In each setup, we solve the problem using our proposed `SignedDifferencesOLS` solver using each of the following libraries: `CVXPY`, `scipy`, and `sklearn`.\n",
    "\n",
    "We also measure the time needed for the solver to complete the problem. We take $n = 10$ in all experiments.\n",
    "\n",
    "Before moving to the experiments, we also quickly demonstrate our vectorization implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization Implementations\n",
    "\n",
    "In what follows, let $P$ be a square matrix of size $n = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57,  0.01, -1.71,  1.47,  0.32],\n",
       "       [ 1.58, -0.29, -0.33,  1.83, -0.03],\n",
       "       [-1.68,  0.67,  1.36,  1.86,  0.61],\n",
       "       [-0.86, -0.14,  0.87,  0.69,  0.85],\n",
       "       [-0.14, -0.94, -0.21,  0.03, -0.  ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "\n",
    "n = 5\n",
    "\n",
    "P = np.round(randn(n, n), 2)\n",
    "\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.lin_alg import half_vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Half Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including The Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57,  0.01, -1.71,  1.47,  0.32, -0.29, -0.33,  1.83, -0.03,\n",
       "        1.36,  1.86,  0.61,  0.69,  0.85, -0.  ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_vectorize(P, triangular='upper', diag=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluding The Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01, -1.71,  1.47,  0.32, -0.33,  1.83, -0.03,  1.86,  0.61,\n",
       "        0.85])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_vectorize(P, triangular='upper', diag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower Half Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including The Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57,  1.58, -0.29, -1.68,  0.67,  1.36, -0.86, -0.14,  0.87,\n",
       "        0.69, -0.14, -0.94, -0.21,  0.03, -0.  ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_vectorize(P, triangular='lower', diag=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluding The Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.58, -1.68,  0.67, -0.86, -0.14,  0.87, -0.14, -0.94, -0.21,\n",
       "        0.03])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_vectorize(P, triangular='lower', diag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed Differences OLS Experiments\n",
    "\n",
    "In what follows, we set $n = 10$ and define the three different solvers to be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solver import SignedDifferencesOLS\n",
    "from utils.data_gen import generate_data\n",
    "\n",
    "n = 10\n",
    "\n",
    "diff_solver = {\n",
    "    'cvxpy' : SignedDifferencesOLS('cvxpy'),\n",
    "    'sklearn' : SignedDifferencesOLS('sklearn'),\n",
    "    'scipy' : SignedDifferencesOLS('scipy')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'positive' : {\n",
    "        'no_noise' : generate_data(n, positive=True),\n",
    "        'noise' : generate_data(n, positive=True, noise=True)\n",
    "    },\n",
    "    'signed' : {\n",
    "        'no_noise' : generate_data(n, positive=False),\n",
    "        'noise' : generate_data(n, positive=False, noise=True)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = {\n",
    "    'positive' : {\n",
    "        'no_noise' : data['positive']['no_noise'].nums,\n",
    "        'noise' : data['positive']['noise'].nums\n",
    "    },\n",
    "    'signed' : {\n",
    "        'no_noise' : data['signed']['no_noise'].nums,\n",
    "        'noise' : data['signed']['noise'].nums\n",
    "    }\n",
    "}\n",
    "diff_matrices = {\n",
    "    'positive' : {\n",
    "        'no_noise' : data['positive']['no_noise'].diff_matrix,\n",
    "        'noise' : data['positive']['noise'].diff_matrix\n",
    "    },\n",
    "    'signed' : {\n",
    "        'no_noise' : data['signed']['no_noise'].diff_matrix,\n",
    "        'noise' : data['signed']['noise'].diff_matrix\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Of The Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.printing import results_message, vectors_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive, No Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_type = 'positive'\n",
    "noise_presence = 'no_noise'\n",
    "\n",
    "X = nums[nums_type][noise_presence]\n",
    "D = diff_matrices[nums_type][noise_presence]\n",
    "\n",
    "X_hat = {\n",
    "    lib : diff_solver[lib].solve(D).sol for lib in diff_solver.keys()\n",
    "}\n",
    "res_norm = {\n",
    "    lib : diff_solver[lib].solve(D).res_norm for lib in diff_solver.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based solution is:\n",
      "    [0.62358598 1.06842574 0.28291727 0.42188553 0.43504838 0.23853265\n",
      " 0.4454705  0.53182311 0.82884285 0.25973484]\n",
      "    The norm of the residual is: 1.1436209663188637e-21.\n",
      "    \n",
      "\n",
      "    The sklearn-based solution is:\n",
      "    [0.38505333 0.82989309 0.04438462 0.18335287 0.19651573 0.\n",
      " 0.20693785 0.29329045 0.59031019 0.02120218]\n",
      "    The norm of the residual is: 1.2216001053570885e-15.\n",
      "    \n",
      "\n",
      "    The scipy-based solution is:\n",
      "    [0.38505333 0.82989309 0.04438462 0.18335287 0.19651573 0.\n",
      " 0.20693785 0.29329045 0.59031019 0.02120218]\n",
      "    The norm of the residual is: 2.4973638151140144e-16.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        results_message(\n",
    "        X_hat[lib], res_norm[lib], lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based OLS solution (X_hat) is:\n",
      "    [0.62358598 1.06842574 0.28291727 0.42188553 0.43504838 0.23853265\n",
      " 0.4454705  0.53182311 0.82884285 0.25973484]\n",
      "    The original vector (X) was:\n",
      "    [0.42966055 0.87450031 0.08899184 0.22796009 0.24112295 0.04460722\n",
      " 0.25154507 0.33789767 0.63491741 0.0658094 ]\n",
      "    The max-norm of their difference is: 0.1939254360684194.\n",
      "    \n",
      "\n",
      "    The sklearn-based OLS solution (X_hat) is:\n",
      "    [0.38505333 0.82989309 0.04438462 0.18335287 0.19651573 0.\n",
      " 0.20693785 0.29329045 0.59031019 0.02120218]\n",
      "    The original vector (X) was:\n",
      "    [0.42966055 0.87450031 0.08899184 0.22796009 0.24112295 0.04460722\n",
      " 0.25154507 0.33789767 0.63491741 0.0658094 ]\n",
      "    The max-norm of their difference is: 0.04460721948162416.\n",
      "    \n",
      "\n",
      "    The scipy-based OLS solution (X_hat) is:\n",
      "    [0.38505333 0.82989309 0.04438462 0.18335287 0.19651573 0.\n",
      " 0.20693785 0.29329045 0.59031019 0.02120218]\n",
      "    The original vector (X) was:\n",
      "    [0.42966055 0.87450031 0.08899184 0.22796009 0.24112295 0.04460722\n",
      " 0.25154507 0.33789767 0.63491741 0.0658094 ]\n",
      "    The max-norm of their difference is: 0.04460721948162416.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        vectors_comparison(\n",
    "        X_hat[lib], X, lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "- Note that the `cvxpy`-based solution performs better than the other two.\n",
    "- In some cases, the `scipy`-based and the `sklearn`-based solutions are identical. (Similar/identical implementations under the hood, perhaps?)\n",
    "- Although the `cvxpy`-based solution produces the solution with the smallest residual norm (by orders of magnitude), the other two solutions are much closer to the original vector $X$ by order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_type = 'positive'\n",
    "noise_presence = 'noise'\n",
    "\n",
    "X = nums[nums_type][noise_presence]\n",
    "D = diff_matrices[nums_type][noise_presence]\n",
    "\n",
    "X_hat = {\n",
    "    lib : diff_solver[lib].solve(D).sol for lib in diff_solver.keys()\n",
    "}\n",
    "res_norm = {\n",
    "    lib : diff_solver[lib].solve(D).res_norm for lib in diff_solver.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based solution is: [0.74070371 0.39567285 0.81576167 1.04869095 0.71177126 0.80741857\n",
      " 0.83174724 0.36637844 1.2106523  1.21636703].\n",
      "    The norm of the residual is: 1.5929376680534574e-07.\n",
      "    \n",
      "\n",
      "    The sklearn-based solution is: [0.37416397 0.02915616 0.44926801 0.68222034 0.34532369 0.44099404\n",
      " 0.46534575 0.         0.8442969  0.85003467].\n",
      "    The norm of the residual is: 0.0007728852602550966.\n",
      "    \n",
      "\n",
      "    The scipy-based solution is: [0.37432527 0.02929441 0.44938323 0.68231251 0.34539282 0.44104013\n",
      " 0.4653688  0.         0.84427386 0.84998859].\n",
      "    The norm of the residual is: 0.0003991162321999125.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        results_message(\n",
    "        X_hat[lib], res_norm[lib], lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_type = 'signed'\n",
    "noise_presence = 'no_noise'\n",
    "\n",
    "X = nums[nums_type][noise_presence]\n",
    "D = diff_matrices[nums_type][noise_presence]\n",
    "\n",
    "X_hat = {\n",
    "    lib : diff_solver[lib].solve(D).sol for lib in diff_solver.keys()\n",
    "}\n",
    "res_norm = {\n",
    "    lib : diff_solver[lib].solve(D).res_norm for lib in diff_solver.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based solution is: [1.55385008 2.48665424 3.95925006 2.62433159 3.12565861 1.09476275\n",
      " 4.20043732 1.44944501 3.20826022 3.36200069].\n",
      "    The norm of the residual is: 1.9876961056974538e-20.\n",
      "    \n",
      "\n",
      "    The sklearn-based solution is: [0.45908731 1.39189142 2.86448716 1.52956876 2.03089576 0.\n",
      " 3.10567442 0.35468224 2.11349736 2.26723783].\n",
      "    The norm of the residual is: 7.992882943171108e-15.\n",
      "    \n",
      "\n",
      "    The scipy-based solution is: [0.45908731 1.39189142 2.86448716 1.52956876 2.03089576 0.\n",
      " 3.10567442 0.35468224 2.11349736 2.26723783].\n",
      "    The norm of the residual is: 2.4490890699602997e-15.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        results_message(\n",
    "        X_hat[lib], res_norm[lib], lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_type = 'positive'\n",
    "noise_presence = 'no_noise'\n",
    "\n",
    "X = nums[nums_type][noise_presence]\n",
    "D = diff_matrices[nums_type][noise_presence]\n",
    "\n",
    "X_hat = {\n",
    "    lib : diff_solver[lib].solve(D).sol for lib in diff_solver.keys()\n",
    "}\n",
    "res_norm = {\n",
    "    lib : diff_solver[lib].solve(D).res_norm for lib in diff_solver.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based solution is: [0.69694447 0.58659862 0.89435223 1.01030242 0.5710543  0.68654638\n",
      " 0.26169359 0.63305442 0.49160716 0.92719282].\n",
      "    The norm of the residual is: 8.734208231075047e-22.\n",
      "    \n",
      "\n",
      "    The sklearn-based solution is: [0.43525089 0.32490503 0.63265864 0.74860884 0.30936072 0.4248528\n",
      " 0.         0.37136083 0.22991357 0.66549923].\n",
      "    The norm of the residual is: 1.969668317248782e-15.\n",
      "    \n",
      "\n",
      "    The scipy-based solution is: [0.43525089 0.32490503 0.63265864 0.74860884 0.30936072 0.4248528\n",
      " 0.         0.37136083 0.22991357 0.66549923].\n",
      "    The norm of the residual is: 9.316605982632408e-16.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        results_message(\n",
    "        X_hat[lib], res_norm[lib], lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive, Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_type = 'positive'\n",
    "noise_presence = 'noise'\n",
    "\n",
    "X = nums[nums_type][noise_presence]\n",
    "D = diff_matrices[nums_type][noise_presence]\n",
    "\n",
    "X_hat = {\n",
    "    lib : diff_solver[lib].solve(D).sol for lib in diff_solver.keys()\n",
    "}\n",
    "res_norm = {\n",
    "    lib : diff_solver[lib].solve(D).res_norm for lib in diff_solver.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based solution is:\n",
      "    [0.81183992 0.967386   1.038925   0.41001198 0.45848949 0.73031176\n",
      " 0.25820401 0.39572738 0.75194365 0.54088415]\n",
      "    The norm of the residual is: 1.1506264303879066e-07.\n",
      "    \n",
      "\n",
      "    The sklearn-based solution is:\n",
      "    [0.5535184  0.70908406 0.78064264 0.15174921 0.20024631 0.47208816\n",
      " 0.         0.13754295 0.4937788  0.28273889]\n",
      "    The norm of the residual is: 0.0006568751109571939.\n",
      "    \n",
      "\n",
      "    The scipy-based solution is:\n",
      "    [0.5536359  0.70918198 0.78072098 0.15180797 0.20028548 0.47210775\n",
      " 0.         0.13752337 0.49373963 0.28268014]\n",
      "    The norm of the residual is: 0.0003392088487034717.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        results_message(\n",
    "        X_hat[lib], res_norm[lib], lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based OLS solution (X_hat) is:\n",
      "    [0.81183992 0.967386   1.038925   0.41001198 0.45848949 0.73031176\n",
      " 0.25820401 0.39572738 0.75194365 0.54088415]\n",
      "    The original vector (X) was:\n",
      "    [0.71443864 0.8700043  0.94156289 0.31266946 0.36116655 0.63300841\n",
      " 0.16092024 0.2984632  0.65469905 0.44365914]\n",
      "    The max-norm of their difference is: 0.09740127635145757.\n",
      "    \n",
      "\n",
      "    The sklearn-based OLS solution (X_hat) is:\n",
      "    [0.5535184  0.70908406 0.78064264 0.15174921 0.20024631 0.47208816\n",
      " 0.         0.13754295 0.4937788  0.28273889]\n",
      "    The original vector (X) was:\n",
      "    [0.71443864 0.8700043  0.94156289 0.31266946 0.36116655 0.63300841\n",
      " 0.16092024 0.2984632  0.65469905 0.44365914]\n",
      "    The max-norm of their difference is: 0.16092024439308505.\n",
      "    \n",
      "\n",
      "    The scipy-based OLS solution (X_hat) is:\n",
      "    [0.5536359  0.70918198 0.78072098 0.15180797 0.20028548 0.47210775\n",
      " 0.         0.13752337 0.49373963 0.28268014]\n",
      "    The original vector (X) was:\n",
      "    [0.71443864 0.8700043  0.94156289 0.31266946 0.36116655 0.63300841\n",
      " 0.16092024 0.2984632  0.65469905 0.44365914]\n",
      "    The max-norm of their difference is: 0.16097899708911745.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        vectors_comparison(\n",
    "        X_hat[lib], X, lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "- Once again, the `cvxpy`-based solution performs better than the other two.\n",
    "    - This time, however, the difference in residual norm is not staggering.\n",
    "- Once again, the `scipy`-based and the `sklearn`-based solutions are identical.\n",
    "- Unlike the previous experiment, the `cvxpy`-based solution is closer to the original vector $X$ than the other two solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signed, No Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_type = 'signed'\n",
    "noise_presence = 'no_noise'\n",
    "\n",
    "X = nums[nums_type][noise_presence]\n",
    "D = diff_matrices[nums_type][noise_presence]\n",
    "\n",
    "X_hat = {\n",
    "    lib : diff_solver[lib].solve(D).sol for lib in diff_solver.keys()\n",
    "}\n",
    "res_norm = {\n",
    "    lib : diff_solver[lib].solve(D).res_norm for lib in diff_solver.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based solution is:\n",
      "    [1.32836184 1.74156221 1.71569584 3.31394428 3.21919259 0.86580543\n",
      " 2.53133878 2.02334307 3.25204675 1.81515595]\n",
      "    The norm of the residual is: 1.281683829121875e-20.\n",
      "    \n",
      "\n",
      "    The sklearn-based solution is:\n",
      "    [0.46255639 0.87575673 0.84989037 2.44813872 2.35338704 0.\n",
      " 1.66553327 1.15753758 2.3862412  0.94935047]\n",
      "    The norm of the residual is: 8.430798925816896e-15.\n",
      "    \n",
      "\n",
      "    The scipy-based solution is:\n",
      "    [0.46255639 0.87575673 0.84989037 2.44813872 2.35338704 0.\n",
      " 1.66553327 1.15753758 2.3862412  0.94935047]\n",
      "    The norm of the residual is: 2.3644026431296272e-15.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        results_message(\n",
    "        X_hat[lib], res_norm[lib], lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based OLS solution (X_hat) is:\n",
      "    [1.32836184 1.74156221 1.71569584 3.31394428 3.21919259 0.86580543\n",
      " 2.53133878 2.02334307 3.25204675 1.81515595]\n",
      "    The original vector (X) was:\n",
      "    [-0.7244907  -0.31129036 -0.33715672  1.26109163  1.16633995 -1.18704709\n",
      "  0.47848618 -0.02950951  1.19919411 -0.23769662]\n",
      "    The max-norm of their difference is: 2.052852641680211.\n",
      "    \n",
      "\n",
      "    The sklearn-based OLS solution (X_hat) is:\n",
      "    [0.46255639 0.87575673 0.84989037 2.44813872 2.35338704 0.\n",
      " 1.66553327 1.15753758 2.3862412  0.94935047]\n",
      "    The original vector (X) was:\n",
      "    [-0.7244907  -0.31129036 -0.33715672  1.26109163  1.16633995 -1.18704709\n",
      "  0.47848618 -0.02950951  1.19919411 -0.23769662]\n",
      "    The max-norm of their difference is: 1.187047089145204.\n",
      "    \n",
      "\n",
      "    The scipy-based OLS solution (X_hat) is:\n",
      "    [0.46255639 0.87575673 0.84989037 2.44813872 2.35338704 0.\n",
      " 1.66553327 1.15753758 2.3862412  0.94935047]\n",
      "    The original vector (X) was:\n",
      "    [-0.7244907  -0.31129036 -0.33715672  1.26109163  1.16633995 -1.18704709\n",
      "  0.47848618 -0.02950951  1.19919411 -0.23769662]\n",
      "    The max-norm of their difference is: 1.1870470891452027.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        vectors_comparison(\n",
    "        X_hat[lib], X, lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "- Once again, the `cvxpy`-based solution performs better than the other two (by orders of magnitude).\n",
    "- Once again, the `scipy`-based and the `sklearn`-based solutions are identical.\n",
    "- As before, although the `cvxpy`-based solution produces the solution with the smallest residual norm, the other two solutions are much closer to the original vector $X$. With that being said, the difference is not as large as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signed, Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_type = 'signed'\n",
    "noise_presence = 'noise'\n",
    "\n",
    "X = nums[nums_type][noise_presence]\n",
    "D = diff_matrices[nums_type][noise_presence]\n",
    "\n",
    "X_hat = {\n",
    "    lib : diff_solver[lib].solve(D).sol for lib in diff_solver.keys()\n",
    "}\n",
    "res_norm = {\n",
    "    lib : diff_solver[lib].solve(D).res_norm for lib in diff_solver.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based solution is:\n",
      "    [1.1458228  2.37753618 4.90626082 3.00741346 3.52743122 4.06116264\n",
      " 1.41958303 2.6386527  2.01213112 2.70718848]\n",
      "    The norm of the residual is: 8.368059772312033e-08.\n",
      "    \n",
      "\n",
      "    The sklearn-based solution is:\n",
      "    [0.         1.23173002 3.76047124 1.86164067 2.38167511 2.91542321\n",
      " 0.27386042 1.49294674 0.86644189 1.56151592]\n",
      "    The norm of the residual is: 0.0005601805436237971.\n",
      "    \n",
      "\n",
      "    The scipy-based solution is:\n",
      "    [0.         1.23171332 3.76043784 1.86159057 2.3816083  2.9153397\n",
      " 0.27376021 1.49282983 0.86630828 1.5613656 ]\n",
      "    The norm of the residual is: 0.0002892759888465662.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        results_message(\n",
    "        X_hat[lib], res_norm[lib], lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The cvxpy-based OLS solution (X_hat) is:\n",
      "    [1.1458228  2.37753618 4.90626082 3.00741346 3.52743122 4.06116264\n",
      " 1.41958303 2.6386527  2.01213112 2.70718848]\n",
      "    The original vector (X) was:\n",
      "    [-1.85869937 -0.62696935  1.90177187  0.0029413   0.52297574  1.05672384\n",
      " -1.58483895 -0.36575264 -0.99225748 -0.29718345]\n",
      "    The max-norm of their difference is: 3.004522170621504.\n",
      "    \n",
      "\n",
      "    The sklearn-based OLS solution (X_hat) is:\n",
      "    [0.         1.23173002 3.76047124 1.86164067 2.38167511 2.91542321\n",
      " 0.27386042 1.49294674 0.86644189 1.56151592]\n",
      "    The original vector (X) was:\n",
      "    [-1.85869937 -0.62696935  1.90177187  0.0029413   0.52297574  1.05672384\n",
      " -1.58483895 -0.36575264 -0.99225748 -0.29718345]\n",
      "    The max-norm of their difference is: 1.8586993712217084.\n",
      "    \n",
      "\n",
      "    The scipy-based OLS solution (X_hat) is:\n",
      "    [0.         1.23171332 3.76043784 1.86159057 2.3816083  2.9153397\n",
      " 0.27376021 1.49282983 0.86630828 1.5613656 ]\n",
      "    The original vector (X) was:\n",
      "    [-1.85869937 -0.62696935  1.90177187  0.0029413   0.52297574  1.05672384\n",
      " -1.58483895 -0.36575264 -0.99225748 -0.29718345]\n",
      "    The max-norm of their difference is: 1.8586993712217044.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lib in diff_solver.keys():\n",
    "    print(\n",
    "        vectors_comparison(\n",
    "        X_hat[lib], X, lib\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "- Note that the `cvxpy`-based solution performs better than the other two.\n",
    "- In some cases, the `scipy`-based and the `sklearn`-based solutions are identical. (Similar/identical implementations under the hood, perhaps?)\n",
    "- Once again, although the `cvxpy`-based solution produces the solution with the smallest residual norm (by orders of magnitude), the other two solutions are much closer to the original vector $X$ by order of magnitude.\n",
    "    - In particular, in this case, the `cvxpy` solution is still fairly noise-robust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
